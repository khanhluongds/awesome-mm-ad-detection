# MisVis: Detecting Misleading Image-Text Pairs (2022)

## ðŸ“„ Paper
**Title**: MisVis: Towards Better Vision-Language Understanding of Misleading Content  
**Link**: https://arxiv.org/abs/2205.03594

## ðŸ§  Summary
MisVis focuses on detecting misleading image-text pairs by assessing both factual and emotional inconsistencies. The authors propose a multi-modal matching and classification system to flag deception.

## ðŸ“Œ Key Contributions
- Defines factual vs emotional inconsistency in image-text pairs
- Proposes multi-task learning setup for classification and explanation
- Introduces a new dataset for misleading vision-language pairs

## ðŸ”¬ Methodology
- Uses vision-language transformers for encoding
- Classifies pairs as factually or emotionally misleading
- Trains on a labeled dataset of news and ad examples

## ðŸ”Ž Relevance to My Work
- Provides a baseline approach for measuring multi-modal ad deception
- Inspiration for my own deception taxonomy and classifier

## ðŸ“Š Dataset & Performance
- 30k+ labeled samples
- High accuracy in detecting mismatches across domains
